#--------------------------------------
# DATA_SETS (workloads). Use a comma to separate two or more different workloads
data_sets=Example4-load_100%-urgent_5%-instance_0.swf, Example4-load_100%-urgent_10%-instance_0.swf, Example4-load_100%-urgent_20%-instance_0.swf
# Data set directory
data_set_dir=/examples/Example4/
# number of gridlets (jobs) to be expected/simulated from the workload file (specify for each data set written above)
total_gridlet=10000,10000,10000,10000,10000,10000,10000,10000,10000,10000,10000,10000,10000

#--------------------------------------
# SCHEDULING ALGORITHMS
# 0 = fair_Strict_Ordering (FCFS-like, no backfill)
# 1 = fair_Aggressive_Backfilling (no reservation)
# 2 = fair_EASY_Backfilling
algorithms = 2

#--------------------------------------
# CHART SETUP (how often is the state of the system sampled)
# how often the results are sampled for charts
sample_tick=600
# if true, charts are shown at the end of the experiment
draw_chart=true
# if true, fairshare related charts are not shown, saving space on screen
only_basic_charts=true
# chart width and height
chart_width = 600
chart_height = 195

#--------------------------------------
# GENERAL CONFIGURATION
# if true, job-to-cluster suitability requirements are enforced
enforce_partition=true
# if true, those jobs requiring "excl" property will always occupy whole nodes
enforce_exclusive_node_allocation_if_requested = false
# if true, ALL jobs allocate whole nodes (no space sharing of multiple jobs on one node). IMPORTANT: this option modifies meaning of input SWF file! "Number of CPUs" becomes number of req. nodes and all machines will have just 1 CPU to speed up simulation!
all_jobs_allocate_whole_nodes=true
# if true, multiple queues are loaded from the description file and job-to-queue mapping is enforced
use_multiple_queues=true
# if true, user groups (and their limits) are enforced upon jobs
use_user_groups=true
# if true, job queues are parsed one-by-one according to queue priority. If false, job queues are only virtual and all jobs are stored in a single big queue (PBS-like feature)
by_queue=true
# if true, results are printed using US-EN convention (decimal part is divided by "."). If false, the decimal part is divided by "," following Czech conventions. 
use_EN_decimal=true

#--------------------------------------
# PREEMPTION and CHECKPOINT CONFIGURATION
# main switch, turns on/off preemption
use_preemption=true
# if true, preempted jobs are requeued
requeue=true
# if true, requeued jobs are started form a checkpoint, i.e., their runtime is shortened (according to already completed part)
use_checkpoint=true

#--------------------------------------
# FAIRSHARE (enabling fairshare increases simulation runtime - periodic updates are driven according to 'fairshare_update_interval' and should be chosen carefully)
# main switch, turns fairsharing on/off
use_fairshare=true
# if true, fairshare usage per each user is periodically decayed
use_decay=true
# fairshare decay interval
decay_interval=48
# fairshare decay factor
decay_factor=0.75
# auxiliary factor to reflect real PBS feature of accounting not 100% of used CPU time
PBS_factor = 0.95
# how often queues are reordered wrt. to fairshare (seconds of simulated real time)
fairshare_update_interval = 60

#--------------------------------------
# RUNTIME ESTIMATES (specify whether i-th algorithm should use runtime estimates and the type of predictor (hold per alg.))  
# estimate = enable/disable the use of estimates, if no predictor chosen, user-provided-estimates are used.
estimate=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
# Predictors are:
# estimateMaxPERC = max-percentage-of-used-walltime-among-past-5-jobs 
# estimateLAST = runtime-of-last-completed-job
# estimateAVG = average-job-runtime
# estimatePERC = average-percentage-of-used-walltime
estimateMaxPERC=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
estimateLAST=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
estimateAVG=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
estimatePERC=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
# used to multiply the default estimate by estimateMaxPERC predictor (to decrease the risk of underestimation)
predictor_increase=1.0

#--------------------------------------
# (OBSOLETE) DYNAMIC DATA_SETS (workloads)
# used for dynamic workloads and hold per set
first_arrival=1420066800,1501538400,1420066800,1501538400,1420066800,1501538400
complain=false

#--------------------------------------
# SIMULATION SPEED
# set to true if maximum schedule size should be limited (to avoid huge update times)
limit_schedule_size = true
# the max. length of schedule in seconds (to speed up simulation).86400
max_schedule_length = 172800
# the max. number of CPUs that can be requested by all waiting jobs in the schedule (to speed up simulation). 
# Example: 1.0 = number of CPUs in system, 2.0 = twice the number of CPUs in the system
max_schedule_CPU_request_factor = 2.0
# disables full schedule compression (job-by-job re-insertion) to speed up simulation
fast_schedule_compression=false
# extracts jobs that cannot run from queue temporarily (MetaCentrum simulation only)
extract_jobs=false

#--------------------------------------
# (OBSOLETE) OLD VISUALISATION setup (slows down simulation when turned-on)
visualize=false
visualize_schedule=false
schedule_repaint_delay=10

#--------------------------------------
# ADDITIONAL CONFIGURATION
pinJobs=false,false,false,false,false
pin_duration=7200
failures=false
use_speeds=false
use_heap=false
baudRate=10000
entities=1

#--------------------------------------
# OPTIMIZATION SCHEDULING STRATEGY
useEventOpt=false
multiplicator=2

#--------------------------------------
# FAIRSHARE OLD (obsolete)
use_fairshare_RAM=false
use_fairshare_WAIT=false
multiply_sums=false
use_MAX=false
use_SQRT=false
sum_multiplications=false

#--------------------------------------
# LIMITS AND FACTORS
time_limit=1000
on_demand_time_limit=100
sld_tresh=10.0
gap_length=0
runtime_minimizer=1.0
arrival_rate_multiplier=1.0

#--------------------------------------
# CONFIGURATION FOR ALGORITHMS AND DATA SETS
#per set
weight_of_fairness=10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10
#per alg.
use_anti_starvation=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
use_resource_spec_packing=false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false
#plugins 
plugins=AverageWaitTimePlugin,AverageSlowdownPlugin
plugin.0.key1=val1
plugin.0.result_header=AvgWaitTimePlugin
plugin.1.key1=val1.1
plugin.1.result_header=AvgSldPlugin